{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a58c1ae",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai tiktoken chromadb langchain esprima faiss-cpu unstructured\n",
    "%pip install \"unstructured[md]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7da0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from git import Repo\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.directory import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.parsers.language import LanguageParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c787ac",
   "metadata": {},
   "source": [
    "Load source code for analysis from file system\n",
    "Langchain currently has limited language parsers. You may need to extend the Langchain libraries for your input languages or fallback to use of DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aecfd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "repo_path = \"../input-src\"\n",
    "\n",
    "#Alternative File loaders dependingon language of code being analysed and availability of specific parsers\n",
    "\n",
    "#loader = GenericLoader.from_filesystem(\n",
    "#    repo_path,\n",
    "#    glob=\"**/*\",\n",
    "#    suffixes=[\".php\"],\n",
    "#    parser=LanguageParser(language=Language.PHP, parser_threshold=50)\n",
    "#)\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    repo_path, recursive=True, glob=\"**/*.php\"\n",
    ")\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676934a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.PHP, \n",
    "                                                               chunk_size=4000, \n",
    "                                                               chunk_overlap=200)\n",
    "texts = python_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01351d7f",
   "metadata": {},
   "source": [
    "Adjustment of k values in document retrieval can have significant impact on performance of model. Too few results leads to insufficient context, too many can lead to misleading or low relevance responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb7b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai_api_type = os.getenv('OPENAI_API_TYPE')\n",
    "openai_api_version = os.getenv('OPENAI_API_VERSION')\n",
    "\n",
    "\n",
    "#from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(disallowed_special=(), \n",
    "                                                   openai_api_base=openai_api_base, \n",
    "                                                   openai_api_key=openai_api_key, \n",
    "                                                   openai_api_type=openai_api_type,\n",
    "                                                   openai_api_version=openai_api_version, chunk_size=16)\n",
    "\n",
    "\n",
    "# generate text embeddings for our target codebase\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 100, \"fetch_k\": 150},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "openai_deploy_name = os.getenv('OPENAI_DEPLOY_NAME')\n",
    "llm = AzureChatOpenAI(deployment_name=openai_deploy_name,\n",
    "                          openai_api_base=openai_api_base,\n",
    "                          openai_api_version=openai_api_version,\n",
    "                          openai_api_key=openai_api_key,\n",
    "                          openai_api_type=openai_api_type,\n",
    "                          temperature=0.7,\n",
    "                          verbose=True)\n",
    "memory = ConversationSummaryMemory(llm=llm,memory_key=\"chat_history\",return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88510c0",
   "metadata": {},
   "source": [
    "Interactively query the codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c95d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add some code to in a loop ask for additional questions and print the answers\n",
    "while True:\n",
    "    question = input(\"Ask a question: \")\n",
    "    if question == \"quit\":\n",
    "        break\n",
    "    print(\"Question: \", question)\n",
    "\n",
    "    result = qa(question)\n",
    "    print(\"Answer: \", result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
